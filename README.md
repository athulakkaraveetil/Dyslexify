# intel-oneAPI

#### Team Name - Brainwave
#### Problem Statement - Open Innovation in Education
#### Team Leader Email - joeljoseph1810@gmail.com
#### Website link - https://joeljjoseph.github.io/Brainwave_Dyslexify/index.html
#### PPT - https://github.com/JoelJJoseph/intel-oneAPI/tree/main/PPT
#### Medium - https://medium.com/@joeljoseph1810/dyslexify-67e45e7e61a6
## DEMO VIDEO - https://youtu.be/bcyEJcy2iyQ
## A Brief of the Prototype <img src="https://github.com/JoelJJoseph/intel-oneAPI/assets/72274851/81390908-eaae-4fb1-bb79-0fa8f96bd15c" height="80" width="80"> <br>

A neurological condition called dyslexia impairs a person's capacity for reading, writing, and spelling. It affects how the brain interprets language, making it challenging for those with dyslexia to understand written content. Between 5% and 20% of Indians suffer with dyslexia, with urban regions having a higher prevalence of the condition. This indicates that millions of Indian school children experience reading and comprehension problems as a result of this disorder. The creation of solutions like our product Dyslexify, a machine learning initiative intended to help people with dyslexia improve their reading and comprehension skills, has been made possible by technological developments using intel’s oneAPI.

<h2>Introducing Dyslexify</h2>
<a href="https://joeljjoseph.github.io/Brainwave_Dyslexify/index.html" target="_blank">
<img src="https://raw.githubusercontent.com/raison024/ArchDiagram/main/Homr.png" alt="Homepage" height="500">
</a>

## Features we Offer <img src="https://github.com/JoelJJoseph/intel-oneAPI/assets/72274851/ab7b93c9-160c-49f1-91f3-853a5aaeaf22" height="80" width="80"> <br>
⭐ 3D model with AR interface usIng oneAPI Rendering toolkit <br>
⭐ Image to speech recognition, text to speech recognition, using SYCL <br>
⭐ ML driven suggestion of books ,using daal4py <br>
⭐ AI Powered Document Assistant, using GPU Strength <br>


## Architecture Diagram <img src="https://github.com/JoelJJoseph/intel-oneAPI/assets/72274851/136f45e1-5d5a-4aa5-b71b-73a644686216" height="80" width="80"> <br>
<img src="https://raw.githubusercontent.com/raison024/ArchDiagram/main/Arch2.png" alt="Logo" height="300">
 


## Tech Stack: <img src="https://github.com/JoelJJoseph/intel-oneAPI/assets/72274851/13362666-adb9-4e7f-ae11-d00ad0339e9e" height="80" width="80"> <br>
* Intel's oneAPI
  * oneDAAL
  * DYC++/SYCL
  * Rendering Toolkit
  	* OSPray and OSPray Studio
* Intel's Devcloud
* Python
* Flask
* JavaScript
* OpenAI
* GPT 3.5
* Blender
* Unity
* WebAR
* PythonAnywhere
   
## Step-by-Step Code Execution Instructions:<img src="https://github.com/JoelJJoseph/intel-oneAPI/assets/72274851/c1f1a73e-3850-4160-8955-2f1311f2a421" height="80" width="80"> <br>

  This Section must contain set of instructions required to clone and run the prototype, so that it can be tested and deeply analysed


## Augmented-Reality Smart Card <img src="https://github.com/JoelJJoseph/intel-oneAPI/assets/72274851/81d0354b-6865-4aff-ab05-9058c5f6a391" height="80" width="80"> <br>
When the AR card is scanned, the user is directed to any one of the of five symbols that represent valued services:
 ⭐ The webpage of Dyslexify.<br>
 ⭐ The AR page to view few 3d model from the website<br>
 ⭐ The PDFGPT to learn better<br>
 ⭐ The book recomendation system<br>
 ⭐ Image to speech application<br>
	
<h2>
 <img src="https://raw.githubusercontent.com/raison024/ArchDiagram/main/card1.jpg" alt="Logo" height="200">
 <img src="https://raw.githubusercontent.com/raison024/ArchDiagram/main/card2.jpg" alt="Logo" height="200">
</h2> 
<br>


<img src="https://codemyui.com/wp-content/uploads/2016/10/pure-css-site-scroll-micro-animation.gif" > <br>

<details> 
  <summary><h2>Dyslexify</h2><img src="https://cdn-icons-png.flaticon.com/128/4406/4406319.png" height="60" width="60"> <br></summary>
<h3>Introduction</h3>
 <img src="https://raw.githubusercontent.com/raison024/ArchDiagram/main/Home2.jpg" alt="Logo" height="500">
 <img src="https://raw.githubusercontent.com/raison024/ArchDiagram/main/Home3.jpg" alt="Logo" height="500">
 <img src="https://raw.githubusercontent.com/raison024/ArchDiagram/main/Home4.jpg" alt="Logo" height="500">
 <img src="https://raw.githubusercontent.com/raison024/ArchDiagram/main/Home5.jpg" alt="Logo" height="500">
<img src="https://raw.githubusercontent.com/raison024/ArchDiagram/main/Home6.jpg" alt="Logo" height="500">
 <br>
  <p>Our project provides informational content on Dyslexia. It gives resources, training sites, and information regarding this disorder. Our goal is to provide families with the resources to create a successful path for people with Dyslexia, it encourages people to look at this disorder as a superpower and not a disease.</p>
 
</details>

<details> 
  <summary><h2>3D Model with AR Interface</h2><img src="https://github.com/JoelJJoseph/intel-oneAPI/assets/72274851/13e37eb3-bfc6-4630-94c3-fc5391f97f0e" height="60" width="60"> <br></summary>
<h3>Introduction</h3>
 <img src="https://raw.githubusercontent.com/raison024/ArchDiagram/main/3D.jpg" alt="Logo" height="500">
 <img src="https://raw.githubusercontent.com/raison024/ArchDiagram/main/3D2.jpg" alt="Logo" height="500">
 <br>
  <p>Bringing 3D models into the learning process and utilizing an augmented reality interface, students can visualize complex concepts, objects, in a more interactive and engaging manner.    This technology enables students to manipulate and explore virtual objects, enhancing their understanding and retention of the subject matter.</p>
 
  <h3>How we did?</h3>
   
✅ The oneAPI Rendering Toolkit is used to create 3D models, which are then hosted on a WebAR platform for easy accessibility.<br><br>
✅ The models are converted into the glTF format and uploaded to the chosen platform. <br><br>
✅ Users can view and interact with the models through web browsers on various devices, without the need for specialized applications or high-end hardware.<br><br>
✅This combination of powerful rendering tools powered by intel oneAPI and WebAR technology provides a seamless experience for individuals to explore and engage with captivating in augmented reality.
   
 <h3>How to run?</h3>
 1. Visit the website or you can scan the QR code.<br><br>
 2. Give the required permissions to view the 3D AR model.<br><br>
 3. Navigate in the 3D space to view the model from different perspectives.<br><br>
</details>

<details>	
  <summary><h2>Image to Speech Recognition</h2><img src="https://github.com/JoelJJoseph/intel-oneAPI/assets/72274851/1668f35c-922e-443b-9a07-38f4f8895025" height="60" width="60"> <br></summary>

  <h3>Introduction</h3>
 <img src="https://raw.githubusercontent.com/raison024/ArchDiagram/main/ImagetoSpeech.jpg" alt="Logo" width="1000">
  <p>This feature enables students to capture images of text, such as medical prescription or text on whiteboards, and convert them into speech. It can assist students with visual    impairments or those who prefer auditory learning, making educational content more accessible.</p>
 
<h3>How we did?</h3>  
✅Create SYCL kernels using the DPC++ programming model provided by the Intel oneAPI Toolkit.<br><br>
✅Compile the SYCL DPC++ code using the DPC++ compiler provided by the Intel oneAPI Toolkit.<br><br>
✅Use ctypes to create a Python wrapper for the compiled C++ code.<br><br>
✅Import the Python wrapper into your Flask application.<br><br>
✅Use the wrapper to call the SYCL DPC++ functions for image processing and speech conversion.<br><br>
 
 <h3>How to run it locally?</h3>
 1. Visit the terminal and type <code>cd Image_to_Speech</code>.<br><br>
 2. Install the packages mentioned in Requirements.txt <code>pip install -r requirements.txt</code><br><br>
 3. Run this command <code>python app.py</code><br><br>
</details>
<details>
	

  <summary><h2>ML driven suggestion of books</h2><img src="https://github.com/JoelJJoseph/intel-oneAPI/assets/72274851/2c22b52d-3971-4c89-83a6-81de23ffbb21" height="60" width="60"> <br></summary>
  <h3>Introduction</h3>
 <img src="https://raw.githubusercontent.com/raison024/ArchDiagram/main/Books.png" alt="Logo" height="400">
 <img src="https://raw.githubusercontent.com/raison024/ArchDiagram/main/Books2.png" alt="Logo" height="400">
 <br>
  <p>With This feature , you can bid farewell to the overwhelming task of choosing your next read. The system analyzes your reading history, genre preferences, favorite authors, you will be able to choose what to read next by selecting the book which you already selected. It shows  similar kind of suggestions.</p>
 
<h3>How we did?</h3>  
✅The daal4py is used here.The main purpose of using daal4py in the project is to leverage the optimized implementations of algorithms provided by oneDAL.<br><br>
✅The oneAPI Data Analytics Library (oneDAL) and its Python wrapper, daal4py, are used for computing cosine similarity between vectors.<br><br>
 
 <h3>How to run?</h3>
 1. Visit this website or use this directory by opening the terminal and type <code>cd bookrec</code> if you want to run locally.<br><br>
 2. Install the packages mentioned in Requirements.txt <code>pip install -r requirements.txt</code><br><br>
 3. Run this command <code>python app.py</code><br><br><br><br>
</details>
<details>
	
  <summary><h2>AI powered Document Assistant</h2><img src="https://github.com/JoelJJoseph/intel-oneAPI/assets/72274851/9765ebd7-e368-4b9e-8408-ce466d0e3e23" height="60" width="60"> <br></summary>
  <h3>Introduction</h3>
 <img src="https://raw.githubusercontent.com/raison024/ArchDiagram/main/pdf1.png" alt="Logo" width="1000">
 <img src="https://raw.githubusercontent.com/raison024/ArchDiagram/main/pdf2.png" alt="Logo" width="1000">
 <img src="https://raw.githubusercontent.com/raison024/ArchDiagram/main/pdf3.png" alt="Logo" width="1000">
 <br>
  <p>This is feature  advanced AI-powered document assistant that revolutionizes the way you search and extract information from PDFs. It eliminates the need for manual searching and scrolling through lengthy documents by leveraging the power of GPT-3.5 and Intel oneApi. With PDFGPT, you can effortlessly ask questions and receive instant answers, allowing for efficient and hassle-free document exploration.</p>
 

<h3>How we did?</h3> <img src="https://github.com/JoelJJoseph/intel-oneAPI/assets/72274851/9765ebd7-e368-4b9e-8408-ce466d0e3e23" height="60" width="60"> <br> 
✅Imports the SYCL context from the daal4py.onea pi module.<br><br>
✅This module provides SYCL functionality for GPU acceleration.<br><br>
✅This flexibility allows you to take advantage of the specific strengths of GPUs while maintaining portability across different hardware architectures.<br><br>
✅It is a game-changing tool for researchers, students, and professionals, providing a seamless and effective solution for working with PDF documents.<br><br>
 
 <h3>How to run?</h3>
 1. Visit the website or the address <code>cd pdfgpt</code> in the this repo.<br><br>
 2. If running locally run this command <code>cd backend</code> after which <code>python app.py</code><br><br>
 3. Go back to the previous directory using <code>cd ../</code> and navigate to frontend directory using the command <code>cd frontend</code><br><br>
 4. Run this command <code>npm start</code>.<br><br>
 5. Run both the terminal simultanously.<br><br>
</details>
  

## What I Learned: <img src="https://github.com/JoelJJoseph/intel-oneAPI/assets/72274851/fb7ba852-f261-4fec-90a7-3fa629f0fee4" height="80" width="80"> <br>
We delve into the key learnings and technologies utilized during the creation of our project. By harnessing a diverse set of cutting-edge technologies, we aimed to develop an innovative solution that seamlessly integrates multiple domains, including SYCL DPC++ using Intel oneAPI, oneDAAL, Intel Rendering Toolkit with OSPRay and OSPRay Studio, Intel DevCloud, Python wrapper framework, Flask, JavaScript Chrome extensions, OpenAI's GPT-3.5, Blender, Unity, and WebAR (Web-based Augmented Reality).

* SYCL DPC++ using Intel oneAPI:
SYCL (Single-source Heterogeneous Programming) and DPC++ (Data Parallel C++) enable efficient parallel programming across different devices and platforms. Leveraging Intel oneAPI, we harnessed the power of these technologies to optimize computation-intensive tasks and achieve high performance.

* oneDAAL:
oneDAAL (oneAPI Data Analytics Library) is a powerful framework for accelerated data analytics. By utilizing oneDAAL, we were able to process and analyze vast amounts of data efficiently, providing valuable insights and improving decision-making capabilities within our project.

* Intel Rendering Toolkit with OSPRay and OSPRay Studio:
Intel Rendering Toolkit offers advanced rendering capabilities for visualizing complex scenes and data. OSPRay, a key component, enabled us to generate stunning visualizations with high fidelity and interactive performance. OSPRay Studio complemented the toolkit by providing a comprehensive environment for creating, editing, and exploring rendered scenes.

* Intel DevCloud:
Intel DevCloud is a cloud-based development platform that provides access to a wide range of Intel hardware resources. We leveraged the power of DevCloud to scale our project, perform large-scale experiments, and optimize performance on diverse hardware configurations.

* Python Wrapper Framework and Flask:
Python Wrapper Frameworks simplify the integration of libraries and APIs into Python applications. By utilizing such a framework, we streamlined the integration of various technologies within our project, allowing for seamless communication and interoperability. Flask, a Python-based web framework, facilitated the development of our project's backend, enabling us to build a robust and scalable web application.

* JavaScript Chrome Extensions:
JavaScript Chrome Extensions enhanced the functionality and user experience of our project by extending the capabilities of the Google Chrome web browser. These extensions enabled us to integrate additional features, customize user interfaces, and interact with external services seamlessly.

* OpenAI's GPT-3.5:
OpenAI's GPT-3.5, an advanced language model, played a pivotal role in our project by providing natural language processing capabilities and generating human-like text. By leveraging GPT-3.5, we enhanced the interactivity and intelligence of our project, enabling dynamic and context-aware user interactions.

* Blender and Unity:
Blender, a powerful 3D creation suite, and Unity, a popular game development platform, empowered us to create visually stunning and interactive experiences within our project. These tools facilitated the creation of immersive environments, realistic simulations, and engaging visual elements.

* WebAR (Web-based Augmented Reality):
WebAR allows users to experience augmented reality directly through web browsers, eliminating the need for dedicated applications. By utilizing WebAR technologies, we expanded the reach and accessibility of our project, enabling users to interact with augmented content using their web browsers and compatible devices.
